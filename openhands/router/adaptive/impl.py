from litellm.types.utils import ModelResponse

from openhands.core.config import ModelRoutingConfig
from openhands.llm.llm import LLM
from openhands.router.adaptive.prompts import SYSTEM_PROMPT, TOOL_DESC, USER_PROMPT
from openhands.router.base import GenerativeRouter


class AdaptiveRouter(GenerativeRouter):
    """
    Router that decides between the actions generated by the default model, a weaker model and a
    reasoning model, which is better for the current turn.
    """

    def __init__(
        self,
        llm: LLM,
        routing_llms: dict[str, LLM],
        model_routing_config: ModelRoutingConfig,
    ):
        super().__init__(llm, routing_llms, model_routing_config)

        self._validate_model_routing_config(model_routing_config, routing_llms)

        self.judge_llm = routing_llms[model_routing_config.judge_llm_config_name]
        self.reasoning_llm = routing_llms[
            model_routing_config.reasoning_llm_config_name
        ]
        self.routed_turns: list[int] = []
        self.cur_turn_num = 0

    def select_best_response(
        self, trajectory: str, responses: list[ModelResponse]
    ) -> ModelResponse:
        messages = [
            {
                'role': 'system',
                'content': SYSTEM_PROMPT,
            },
            {
                'role': 'user',
                'content': USER_PROMPT.format(
                    trajectory=trajectory,
                    action_1='',  # FIXME:
                    action_2='',  # FIXME:
                    action_3='',  # FIXME:
                    tool_description=TOOL_DESC,
                ),
            },
        ]

        response = self.judge_llm.completion(
            messages=messages,
        )
        chosen_action = self._parse_chosen_action(response.choices[0].message.content)
        return responses[chosen_action]

    def _parse_chosen_action(self, response: str) -> int:
        return int(response[response.find('[[') + 2 : response.find(']]')])

    def _validate_model_routing_config(
        self, model_routing_config: ModelRoutingConfig, routing_llms: dict[str, LLM]
    ):
        if (
            not model_routing_config.judge_llm_config_name
            or not model_routing_config.reasoning_llm_config_name
            or not model_routing_config.weak_llm_config_name
        ):
            raise ValueError(
                'Judge LLM, Weak LLM and Reasoning LLM config names must be provided'
            )
        if model_routing_config.judge_llm_config_name not in routing_llms:
            raise ValueError(
                f'Judge LLM config {model_routing_config.judge_llm_config_name} not found'
            )
        if model_routing_config.reasoning_llm_config_name not in routing_llms:
            raise ValueError(
                f'Reasoning LLM config {model_routing_config.reasoning_llm_config_name} not found'
            )
        if model_routing_config.weak_llm_config_name not in routing_llms:
            raise ValueError(
                f'Weak LLM config {model_routing_config.weak_llm_config_name} not found'
            )
